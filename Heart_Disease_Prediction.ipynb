{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file\n",
    "\n",
    "raw_data = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll find the unique values of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "number_of_unique_values = raw_data['target'].unique()\n",
    "\n",
    "print(number_of_unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a thumb rule that 75% data should be training data and 25% data should be testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = raw_data.iloc[0:int(0.75*len(raw_data))]\n",
    "\n",
    "training_data = pd.DataFrame(training_data)\n",
    "\n",
    "testing_data = raw_data.iloc[int(0.75*len(raw_data)):]\n",
    "\n",
    "testing_data = pd.DataFrame(testing_data)\n",
    "\n",
    "actual_class = testing_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns having 0 or minimum variance are removed from the data in PCA because the probability of these columns will always be 1 and taking log of them will result in 0 which means they're not participating in determining the posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbs            0.127909\n",
      "exang          0.186659\n",
      "target         0.199407\n",
      "sex            0.232973\n",
      "restecg        0.259561\n",
      "thal           0.311450\n",
      "slope          0.399789\n",
      "ca             0.893026\n",
      "cp             1.020116\n",
      "oldpeak        1.260725\n",
      "age           85.141710\n",
      "trestbps     277.419438\n",
      "thalach      437.177966\n",
      "chol        2763.491092\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_variances = training_data.var()\n",
    "\n",
    "feature_variances.sort_values(inplace=True)\n",
    "\n",
    "print(feature_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.drop(labels = ['fbs','exang','sex','restecg','thal','slope','ca','cp','oldpeak'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll determine the mean vector and covariance matrix for the formula of Joint Gaussian Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vector_and_cov_mat(target_value):\n",
    "    \n",
    "    target_data = training_data[training_data['target'] == target_value]\n",
    "    \n",
    "    dropped_target_data = target_data.drop(['target'],axis=1)\n",
    "    \n",
    "    target_data_array = np.array(dropped_target_data)\n",
    "    \n",
    "    mean_vector = np.mean(target_data_array,axis=0)\n",
    "    \n",
    "    cov_mat = dropped_target_data.cov()\n",
    "    \n",
    "    return [mean_vector,cov_mat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural parameters include mean vector, covariance matrix and prior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([ 52.4969697 , 129.3030303 , 242.23030303, 158.46666667]),                  age    trestbps         chol     thalach\n",
      "age        91.214930   42.421656   131.525092  -96.288211\n",
      "trestbps   42.421656  261.456393    80.783444    8.693089\n",
      "chol      131.525092   80.783444  2867.910052   14.843089\n",
      "thalach   -96.288211    8.693089    14.843089  367.652846], [array([ 56.88709677, 133.        , 251.56451613, 140.90322581]),                 age    trestbps         chol     thalach\n",
      "age       55.970650   45.311475    95.572977   -9.896351\n",
      "trestbps  45.311475  314.786885   237.000000  -35.344262\n",
      "chol      95.572977  237.000000  2463.692491   21.596510\n",
      "thalach   -9.896351  -35.344262    21.596510  403.367530]]\n"
     ]
    }
   ],
   "source": [
    "natural_parameters = list(map(lambda x: mean_vector_and_cov_mat(x),number_of_unique_values))\n",
    "\n",
    "print(natural_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7268722466960352, 0.27312775330396477]\n"
     ]
    }
   ],
   "source": [
    "prior_class_probabilities = list(map(lambda target_value: len(training_data[training_data['target'] == target_value])/len(training_data),\n",
    "                                     number_of_unique_values))\n",
    "\n",
    "print(prior_class_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dict(zip(number_of_unique_values,natural_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,p_cap in zip(D.keys(),prior_class_probabilities):\n",
    "    \n",
    "    D[k].append(p_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 52.4969697 , 129.3030303 , 242.23030303, 158.46666667]),\n",
       "                  age    trestbps         chol     thalach\n",
       " age        91.214930   42.421656   131.525092  -96.288211\n",
       " trestbps   42.421656  261.456393    80.783444    8.693089\n",
       " chol      131.525092   80.783444  2867.910052   14.843089\n",
       " thalach   -96.288211    8.693089    14.843089  367.652846,\n",
       " 0.7268722466960352]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_cov = 0\n",
    "\n",
    "for i in [0,1]:\n",
    "    \n",
    "    pooled_cov += D[i][1]*(len(training_data[training_data['target'] == i])-1)\n",
    "    \n",
    "pooled_cov = pooled_cov/(len(training_data)-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_Classifier_Result(heart_features):\n",
    "    \n",
    "    numerators = list(map(lambda target_value: ((s.multivariate_normal.pdf(x=heart_features,\n",
    "                                                          mean=D[target_value][0],cov=pooled_cov))*D[target_value][2]),D.keys()))\n",
    "    \n",
    "    numerators = np.array(numerators)\n",
    "    \n",
    "    posterior_class_probabilities = list(map(lambda x: numerators[x]/np.sum(numerators),[0,1]))\n",
    "    \n",
    "    return (np.argmax(posterior_class_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data.drop(labels=['target'],axis=1,inplace=True)\n",
    "\n",
    "testing_data = testing_data.drop(labels = ['fbs','exang','sex','restecg','thal','slope','ca','cp','oldpeak'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = 0\n",
    "\n",
    "false_values = 0\n",
    "\n",
    "for i in range(0,len(testing_data)):\n",
    "    \n",
    "    predicted_class = Naive_Bayes_Classifier_Result(testing_data.iloc[i,:])\n",
    "    \n",
    "    if predicted_class == actual_class.iloc[i]:\n",
    "        \n",
    "        true_values += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        false_values += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = true_values/(true_values+false_values)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.78947368421053"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
